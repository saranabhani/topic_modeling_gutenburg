{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Installing the required libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e2486c8dbb9d166"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install pandas numpy matplotlib nltk scikit-learn"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0fc0a91feaec4c1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing the required libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b9e003a65de8c9b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "import spacy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2288ff29ecd3705",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6bfe0e4b7ce897a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the text data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8df5de7cc58a5d1c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the corpus: return a list of text data and a list of filenames\n",
    "def load_corpus(folder_path):\n",
    "    corpus = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        try:\n",
    "            if filename.endswith(\".txt\"):\n",
    "                with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
    "                    corpus.append(file.read())\n",
    "                    filenames.append(filename)\n",
    "        except:\n",
    "            print(f'Error reading file: {filename}')\n",
    "    return corpus, filenames"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c582cc562693a38",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "folder_path = 'books'\n",
    "corpus, filenames = load_corpus(folder_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7891cabb38e2bbb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Number of documents: {len(corpus)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a4e4fbede7d3e4a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Topic Modeling 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d864cd3927aa8a6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vectorizing the text data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad66497f949e30d4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(encoding='utf-8', lowercase=True, max_df=0.95, min_df=3, max_features=2500)\n",
    "corpus_vectorized = tfidf_vectorizer.fit_transform(corpus)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cfeaf69a6cf88c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "659772bf34e17304",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Number of features: {len(tfidf_feature_names)}\")\n",
    "print(f\"First 10 features: {tfidf_feature_names[:10]}\")\n",
    "print(f\"Last 10 features: {tfidf_feature_names[-10:]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60b9345a35c23712",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the NMF model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "198411232b699c0c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=4, random_state=1)\n",
    "nmf.fit(corpus_vectorized)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf0ca3e5c26a5c63",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizing the topics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa76f5c0bc94ea0b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_top_words(model, feature_names, n_top_words, title):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(30, 15), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[-n_top_words:]\n",
    "        top_features = feature_names[top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7)\n",
    "        ax.set_title(f\"Topic {topic_idx +1}\", fontdict={\"fontsize\": 30})\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "        for i in \"top right left\".split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fc4aaca9c1c2842",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_top_words = 30\n",
    "plot_top_words(nmf, tfidf_feature_names, n_top_words, 'Topics in NMF model')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae4f9e528f61dffd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# document topic distribution\n",
    "doc_topic_dist = nmf.transform(corpus_vectorized)\n",
    "df = pd.DataFrame(doc_topic_dist, columns=[\"Topic 1\", \"Topic 2\", \"Topic 3\", \"Topic 4\"])\n",
    "df['filename'] = filenames\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "853f7f7b758e3f28",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Topic Modeling 2: Removing stopwords"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "537f98d6e00d75f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing the text data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec6b9f351c13ec04"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_text(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word.lower() for word in word_tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fda114f8f5c9e567",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "corpus_preprocessed = [preprocess_text(text) for text in corpus]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "839ba4ef7e1791e6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(corpus_preprocessed[1])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c168ad381145d61",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vectorizing the preprocessed text data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c224ac1c29a936"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "corpus_vectorized = tfidf_vectorizer.fit_transform(corpus_preprocessed)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "840a303be189fc71",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d02db546d35e581a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Number of features: {len(tfidf_feature_names)}\")\n",
    "print(f\"First 10 features: {tfidf_feature_names[:10]}\")\n",
    "print(f\"Last 10 features: {tfidf_feature_names[-10:]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d6e62b5cc1849c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the NMF model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53bbe57de892b8d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nmf.fit(corpus_vectorized)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0b38f477ca13efd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_top_words(nmf, tfidf_feature_names, n_top_words, 'Topics in NMF model')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf530f81a7b2338c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# document topic distribution\n",
    "doc_topic_dist = nmf.transform(corpus_vectorized)\n",
    "df = pd.DataFrame(doc_topic_dist, columns=[\"Topic 1\", \"Topic 2\", \"Topic 3\", \"Topic 4\"])\n",
    "df['filename'] = filenames\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7baf8a31fbf91e59",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Topic Modeling 3: + Lemmatization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcfab077771cd122"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## preprocessing the text data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2321725a7c641711"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    filtered_text = [lemmatizer.lemmatize(word.lower()) for word in word_tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66b050c41e67745",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "corpus_preprocessed = [preprocess_text(text) for text in corpus]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfc9e7d9773a2936",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(corpus_preprocessed[1])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd1aeb93a1f0efa8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vectorizing the preprocessed text data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a5d565a1edfd499"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "corpus_vectorized = tfidf_vectorizer.fit_transform(corpus_preprocessed)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3443a79a338888e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfa4fda255e16bf9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Number of features: {len(tfidf_feature_names)}\")\n",
    "print(f\"First 10 features: {tfidf_feature_names[:10]}\")\n",
    "print(f\"Last 10 features: {tfidf_feature_names[-10:]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15faac96e049a0d2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the NMF model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "587701dcda8afab7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nmf.fit(corpus_vectorized)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee5756533afa75c5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_top_words(nmf, tfidf_feature_names, n_top_words, 'Topics in NMF model')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c68ff33a91f13f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# document topic distribution\n",
    "doc_topic_dist = nmf.transform(corpus_vectorized)\n",
    "df = pd.DataFrame(doc_topic_dist, columns=[\"Topic 1\", \"Topic 2\", \"Topic 3\", \"Topic 4\"])\n",
    "df['filename'] = filenames\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb16d2f3c18176c9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Topic Modeling 4: + Entities Masking"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2615135c3a6b51a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing the text data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "564ea98a91f2bc27"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_text = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct and not token.is_space and token.is_alpha:\n",
    "            if token.ent_type_ in ['PERSON', 'ORG', 'GPE'] or token.pos_ in ['PROPN', 'NUM', 'SYM']:\n",
    "                filtered_text.append('MASKED')\n",
    "            elif token.pos_ in ['DET', 'ADP', 'CCONJ', 'PRON', 'AUX', 'PART', 'PUNCT', 'INTJ']:\n",
    "                continue\n",
    "            else:\n",
    "                filtered_text.append(token.lemma_.lower())\n",
    "    return ' '.join(filtered_text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4def68d12734697",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nlp.max_length = 4000000"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0ec73bab7e50a79",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "corpus_preprocessed = [preprocess_text(text) for text in corpus]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9f8c46477609a4e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(corpus_preprocessed[1])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25a1d2f9e6c392e5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vectorizing the preprocessed text data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65ff68536d2dd20f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "corpus_vectorized = tfidf_vectorizer.fit_transform(corpus_preprocessed)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3caeb88c27a4490",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c09213fd94d62ebc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f\"Number of features: {len(tfidf_feature_names)}\")\n",
    "print(f\"First 10 features: {tfidf_feature_names[:10]}\")\n",
    "print(f\"Last 10 features: {tfidf_feature_names[-10:]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e92e4afd0c5494c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the NMF model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25da578e846a8fd7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nmf.fit(corpus_vectorized)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5896874415601a45",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_top_words(nmf, tfidf_feature_names, n_top_words, 'Topics in LDA model')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5ef9d23e3db24fd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# document topic distribution\n",
    "doc_topic_dist = nmf.transform(corpus_vectorized)\n",
    "df = pd.DataFrame(doc_topic_dist, columns=[\"Topic 1\", \"Topic 2\", \"Topic 3\", \"Topic 4\"])\n",
    "df['filename'] = filenames\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acb2664a870a9161",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "17495ae59c426864"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
